make clean
make[1]: Entering directory '/work/gitlab/tensorrt-cookbook-in-chinese/06-PluginAndParser/pyTorch-LayerNorm'
rm -rf ./*.d ./*.o ./*.so ./*.plan
make[1]: Leaving directory '/work/gitlab/tensorrt-cookbook-in-chinese/06-PluginAndParser/pyTorch-LayerNorm'
python './pyTorchToTensorRT.py'
make[1]: Entering directory '/work/gitlab/tensorrt-cookbook-in-chinese/06-PluginAndParser/pyTorch-LayerNorm'
/usr/local/cuda//bin/nvcc -std=c++11 -DNDEBUG -O3 -arch=sm_61 -I. -I/usr/local/cuda//include -I/usr/lib/x86_64-linux-gnu//include -M -MT LayerNormPlugin.o -o LayerNormPlugin.d LayerNormPlugin.cu
/usr/local/cuda//bin/nvcc -std=c++11 -DNDEBUG -O3 -arch=sm_61 -I. -I/usr/local/cuda//include -I/usr/lib/x86_64-linux-gnu//include -Xcompiler -fPIC -o LayerNormPlugin.o -c LayerNormPlugin.cu
/usr/local/cuda//bin/nvcc -std=c++11 -DNDEBUG -O3 -arch=sm_61 -shared -L/usr/local/cuda//lib64 -lcudart -L/usr/lib/x86_64-linux-gnu//lib -lnvinfer -o LayerNormPlugin.so LayerNormPlugin.o
rm LayerNormPlugin.o
make[1]: Leaving directory '/work/gitlab/tensorrt-cookbook-in-chinese/06-PluginAndParser/pyTorch-LayerNorm'
Succeeded building model in pyTorch!
graph(%x : Float(*, 3, 4, 5, strides=[60, 20, 5, 1], requires_grad=0, device=cuda:0)):
  %1 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %2 : Float(*, 3, 4, 5, strides=[60, 20, 5, 1], requires_grad=0, device=cuda:0) = onnx::Mul(%x, %1)
  %3 : Float(*, device=cpu) = onnx::ReduceMean[axes=[-3, -2, -1]](%2)
  %4 : Float(*, 3, 4, *, device=cpu) = onnx::Sub(%2, %3)
  %5 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()
  %6 : Float(*, 3, 4, *, device=cpu) = onnx::Pow(%4, %5)
  %7 : Float(*, device=cpu) = onnx::ReduceMean[axes=[-3, -2, -1]](%6)
  %8 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()
  %9 : Float(*, device=cpu) = onnx::Add(%7, %8)
  %10 : Float(*, device=cpu) = onnx::Sqrt(%9)
  %11 : Float(*, 3, 4, *, strides=[60, 20, 5, 1], requires_grad=0, device=cuda:0) = onnx::Div(%4, %10) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:2347:0
  %12 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()
  %y : Float(*, 3, 4, *, strides=[60, 20, 5, 1], requires_grad=0, device=cuda:0) = onnx::Mul(%11, %12)
  return (%y)

Succeeded converting model into onnx!
Succeeded replacing LayerNorm Plugin node!
Succeeded building LayerNorm Plugin!
Succeeded finding onnx file!
Succeeded parsing onnx file!
Succeeded building engine!
EngineBinding0-> (-1, 3, 4, 5) DataType.FLOAT
EngineBinding1-> (-1, 3, 4, 5) DataType.FLOAT
inputH0 : (2, 3, 4, 5)
outputH0: (2, 3, 4, 5)
[[[[-1.7034 -1.6457 -1.5879 -1.5302 -1.4724]
   [-1.4147 -1.357  -1.2992 -1.2415 -1.1837]
   [-1.126  -1.0682 -1.0105 -0.9528 -0.895 ]
   [-0.8373 -0.7795 -0.7218 -0.664  -0.6063]]

  [[-0.5486 -0.4908 -0.4331 -0.3753 -0.3176]
   [-0.2598 -0.2021 -0.1444 -0.0866 -0.0289]
   [ 0.0289  0.0866  0.1444  0.2021  0.2598]
   [ 0.3176  0.3753  0.4331  0.4908  0.5486]]

  [[ 0.6063  0.664   0.7218  0.7795  0.8373]
   [ 0.895   0.9528  1.0105  1.0682  1.126 ]
   [ 1.1837  1.2415  1.2992  1.357   1.4147]
   [ 1.4724  1.5302  1.5879  1.6457  1.7034]]]


 [[[-1.7034 -1.6457 -1.5879 -1.5302 -1.4724]
   [-1.4147 -1.357  -1.2992 -1.2415 -1.1837]
   [-1.126  -1.0682 -1.0105 -0.9528 -0.895 ]
   [-0.8373 -0.7795 -0.7218 -0.664  -0.6063]]

  [[-0.5486 -0.4908 -0.4331 -0.3753 -0.3176]
   [-0.2598 -0.2021 -0.1444 -0.0866 -0.0289]
   [ 0.0289  0.0866  0.1444  0.2021  0.2598]
   [ 0.3176  0.3753  0.4331  0.4908  0.5486]]

  [[ 0.6063  0.664   0.7218  0.7795  0.8373]
   [ 0.895   0.9528  1.0105  1.0682  1.126 ]
   [ 1.1837  1.2415  1.2992  1.357   1.4147]
   [ 1.4724  1.5302  1.5879  1.6457  1.7034]]]]
Succeeded running model in TensorRT!
